{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Indlæsning af Data:**\n",
    "    ```python\n",
    "    dataset = pd.read_csv('../modified_dataset.csv', sep=',', encoding='utf-8')\n",
    "    ```\n",
    "    - Data indlæses fra en CSV-fil uden at specificere kolonnenavne, da CSV-filen indeholder overskrifter.\n",
    "\n",
    "2. **Konvertering af 'Incidents'-kolonnen til Numerisk:**\n",
    "    ```python\n",
    "    dataset['Incidents'] = pd.to_numeric(dataset['Incidents'], errors='coerce')\n",
    "    ```\n",
    "    - Kolonnen 'Incidents' konverteres til numerisk datatype, og eventuelle konverteringsfejl håndteres ved at sætte dem til NaN.\n",
    "\n",
    "3. **Fjernelse af Rækker med Ikke-Numeriske Værdier:**\n",
    "    ```python\n",
    "    dataset = dataset.dropna(subset=['Incidents'])\n",
    "    ```\n",
    "    - Evt Rækker, som er 'NULL', fjernes.\n",
    "\n",
    "4. **Sikring af at 'Incidents'-kolonnen er af Integer-Type:**\n",
    "    ```python\n",
    "    dataset['Incidents'] = dataset['Incidents'].astype(int)\n",
    "    ```\n",
    "    - Kolonnen 'Incidents' sikres at være af integer-type.\n",
    "\n",
    "5. **Fjernelse af Rækker med 0 Hændelser:**\n",
    "    ```python\n",
    "    dataset = dataset[dataset['Incidents'] > 0]\n",
    "    ```\n",
    "    - Rækker, hvor hændelsestallet er 0 og der derved ikke er sket noget uheld, fjernes fra datasættet.\n",
    "\n",
    "6. **Udvidelse af DataFrame:**\n",
    "    ```python\n",
    "    repeated_dataset = dataset.loc[dataset.index.repeat(dataset['Incidents'])]\n",
    "    ```\n",
    "    - DataFrame udvides ved at gentage rækkerne baseret på værdien i antal 'Incidents'-kolonnen.\n",
    "\n",
    "7. **Fjernelse af 'Incidents'-kolonnen:**\n",
    "    ```python\n",
    "    repeated_dataset.drop(columns=['Incidents'], inplace=True)\n",
    "    ```\n",
    "    - 'Incidents'-kolonnen fjernes, da den ikke længere er nødvendig.\n",
    "\n",
    "8. **Output og Gemme det Transformerede Datasæt:**\n",
    "    ```python\n",
    "    print(repeated_dataset.head())\n",
    "    repeated_dataset.to_csv('../expanded_dataset.csv', index=False)\n",
    "    ```\n",
    "    - Resultatet vises for at kontrollere den korrekte transformation, og det transformerede datasæt gemmes i en ny CSV-fil som vi nu kan bruge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Gender      Age Type of Injury                Area       Type of Vehicle\n",
      "0   Mænd  0-17 år         Dræbte  Region Hovedstaden  Almindelig personbil\n",
      "0   Mænd  0-17 år         Dræbte  Region Hovedstaden  Almindelig personbil\n",
      "8   Mænd  0-17 år         Dræbte  Region Hovedstaden              Knallert\n",
      "9   Mænd  0-17 år         Dræbte  Region Hovedstaden                 Cykel\n",
      "9   Mænd  0-17 år         Dræbte  Region Hovedstaden                 Cykel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data from CSV without specifying column names if the CSV includes headers\n",
    "dataset = pd.read_csv('../modified_dataset.csv', sep=',', encoding='utf-8')\n",
    "\n",
    "# Convert 'Incidents' column to numeric, coercing errors\n",
    "dataset['Incidents'] = pd.to_numeric(dataset['Incidents'], errors='coerce')\n",
    "\n",
    "# Drop any rows that could not be converted to numbers (if there were non-numeric values)\n",
    "dataset = dataset.dropna(subset=['Incidents'])\n",
    "\n",
    "# Ensure 'Incidents' column is of integer type\n",
    "dataset['Incidents'] = dataset['Incidents'].astype(int)\n",
    "\n",
    "# Remove rows where the 'Incidents' count is 0\n",
    "dataset = dataset[dataset['Incidents'] > 0]\n",
    "\n",
    "# Explode the DataFrame to repeat rows based on the 'Incidents' column\n",
    "repeated_dataset = dataset.loc[dataset.index.repeat(dataset['Incidents'])]\n",
    "\n",
    "# Drop the 'Incidents' column as it is no longer needed\n",
    "repeated_dataset.drop(columns=['Incidents'], inplace=True)\n",
    "\n",
    "# Output the result to check\n",
    "print(repeated_dataset.head())\n",
    "\n",
    "# Optionally, save the transformed dataset to a new CSV file\n",
    "repeated_dataset.to_csv('../expanded_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Import af nødvendige biblioteker:**\n",
    "    ```python\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.metrics import classification_report, accuracy_score\n",
    "    import graphviz\n",
    "    ```\n",
    "\n",
    "2. **Forberedelse af data:**\n",
    "    ```python\n",
    "    X = repeated_dataset.drop('Type of Injury', axis=1)\n",
    "    y = repeated_dataset['Type of Injury']\n",
    "    ```\n",
    "    - `X` indeholder alle input features undtagen `Type of Injury`, som er vores målvariabel.\n",
    "    - `y` indeholder kun `Type of Injury`, som vi vil forudsige.\n",
    "\n",
    "3. **Kodning af kategoriske data:**\n",
    "    ```python\n",
    "    label_encoders = {}\n",
    "    for column in X.columns:\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "    ```\n",
    "    - Hver kolonne i `X` kodet til numeriske værdier ved hjælp af `LabelEncoder`.\n",
    "\n",
    "4. **Opdeling af data i trænings- og testdatasæt:**\n",
    "    ```python\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    ```\n",
    "    - Data opdeles i træningssæt (70%) og testsæt (30%) ved hjælp af `train_test_split`.\n",
    "\n",
    "5. **Initialisering og træning af beslutningstræ-klassifikatoren:**\n",
    "    ```python\n",
    "    tree_classifier = DecisionTreeClassifier(random_state=42)\n",
    "    tree_classifier.fit(X_train, y_train)\n",
    "    ```\n",
    "    - dtree-klassifikatoren initialiseres og trænes med træningsdata.\n",
    "\n",
    "6. **Forudsigelser og evalueringer:**\n",
    "    ```python\n",
    "    y_pred = tree_classifier.predict(X_test)\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "    ```\n",
    "    - Klassifikationsrapport og nøjagtighedsscore udskrives for at evaluere modellens præstation på testdata.\n",
    "\n",
    "7. **Visualisering af beslutningstræet:**\n",
    "    ```python\n",
    "    dot_data = export_graphviz(tree_classifier, out_file=None, \n",
    "                               feature_names=X.columns,  \n",
    "                               class_names=tree_classifier.classes_,\n",
    "                               filled=True, rounded=True, special_characters=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    graph.render('decision_tree_improved', format='png')\n",
    "    ```\n",
    "    - dtree'et eksporteres som en grafisk repræsentation ved hjælp af `export_graphviz` og gemmes som en PNG-fil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "Alvorligt tilskadekomne       0.62      0.82      0.71      1499\n",
      "                 Dræbte       0.29      0.03      0.05       146\n",
      "  Lettere tilskadekomne       0.48      0.29      0.36       922\n",
      "\n",
      "               accuracy                           0.59      2567\n",
      "              macro avg       0.46      0.38      0.37      2567\n",
      "           weighted avg       0.55      0.59      0.55      2567\n",
      "\n",
      "Accuracy Score: 0.5862874951305025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.752037 to fit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'decision_tree_improved.png'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import graphviz\n",
    "\n",
    "# Assuming 'repeated_dataset' is already loaded\n",
    "# Load your data if it's not loaded\n",
    "# repeated_dataset = pd.read_csv('../expanded_dataset.csv')\n",
    "\n",
    "# Prepare the data\n",
    "X = repeated_dataset.drop('Type of Injury', axis=1)\n",
    "y = repeated_dataset['Type of Injury']\n",
    "\n",
    "# Encode categorical data\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    le = LabelEncoder()\n",
    "    X[column] = le.fit_transform(X[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the decision tree classifier\n",
    "tree_classifier = DecisionTreeClassifier(random_state=42)\n",
    "tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and Evaluations\n",
    "y_pred = tree_classifier.predict(X_test)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Visualize the decision tree\n",
    "dot_data = export_graphviz(tree_classifier, out_file=None, \n",
    "                           feature_names=X.columns,  \n",
    "                           class_names=tree_classifier.classes_,\n",
    "                           filled=True, rounded=True, special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render('decision_tree_improved', format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Definition af `predict_injury`-funktionen:**\n",
    "    ```python\n",
    "    def predict_injury(gender, age, area, type_of_vehicle):\n",
    "        # Create a DataFrame for the input features\n",
    "        input_data = pd.DataFrame({\n",
    "            'Gender': [gender],\n",
    "            'Age': [age],\n",
    "            'Area': [area],\n",
    "            'Type of Vehicle': [type_of_vehicle]\n",
    "        })\n",
    "    ```\n",
    "    - Funktionen starter med at skabe en DataFrame `input_data` med de fire inputparametre: køn, alder, region og køretøjstype.\n",
    "\n",
    "2. **Kodning af inputdata:**\n",
    "    ```python\n",
    "    # Encode the input data using the same label encoders used for training\n",
    "    for column, le in label_encoders.items():\n",
    "        input_data[column] = le.transform(input_data[column])\n",
    "    ```\n",
    "    - Hver kolonne i `input_data` bliver kodet til numeriske værdier ved hjælp af de samme `LabelEncoder`-objekter, som blev brugt under træningen af modellen. Dette sikrer konsistens mellem trænings- og forudligelse.\n",
    "\n",
    "3. **Forudsigelse ved hjælp af beslutningstræ-modellen:**\n",
    "    ```python\n",
    "    # Make prediction\n",
    "    prediction = tree_classifier.predict(input_data)\n",
    "    ```\n",
    "    - Den trænede model (`tree_classifier`) bruges til at forudsige typen af skade baseret på de en-kodede inputdata.\n",
    "\n",
    "4. **Returnering af forudsagt klasse:**\n",
    "    ```python\n",
    "    # Get the predicted class label\n",
    "    predicted_class = prediction[0]\n",
    "    return predicted_class\n",
    "    ```\n",
    "    - Den forudsagte klasse (`predicted_class`) hentes fra resultatet af forudsigelsen og returneres.\n",
    "\n",
    "5. **Eksempel på brug af funktionen:**\n",
    "    ```python\n",
    "    # Example usage:\n",
    "    predicted_injury = predict_injury('Kvinder', '18-24 år', 'Region Hovedstaden', 'Almindelig personbil')\n",
    "    print(\"Predicted Type of Injury:\", predicted_injury)\n",
    "    ```\n",
    "    - Et eksempel på, hvordan funktionen kan bruges, vises ved at kalde `predict_injury` med specifikke inputværdier og udskrive den forudsagte type skade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Type of Injury: Alvorligt tilskadekomne\n"
     ]
    }
   ],
   "source": [
    "def predict_injury(gender, age, area, type_of_vehicle):\n",
    "    # Create a DataFrame for the input features\n",
    "    input_data = pd.DataFrame({\n",
    "        'Gender': [gender],\n",
    "        'Age': [age],\n",
    "        'Area': [area],\n",
    "        'Type of Vehicle': [type_of_vehicle]\n",
    "    })\n",
    "    \n",
    "    # Encode the input data using the same label encoders used for training\n",
    "    for column, le in label_encoders.items():\n",
    "        input_data[column] = le.transform(input_data[column])\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = tree_classifier.predict(input_data)\n",
    "    \n",
    "    # Get the predicted class label\n",
    "    predicted_class = prediction[0]\n",
    "    return predicted_class\n",
    "\n",
    "# Example usage:\n",
    "predicted_injury = predict_injury('Kvinder', '18-24 år', 'Region Hovedstaden', 'Almindelig personbil')\n",
    "print(\"Predicted Type of Injury:\", predicted_injury)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Import af nødvendige moduler:**\n",
    "    ```python\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    ```\n",
    "\n",
    "2. **Definering af parametergrid:**\n",
    "    ```python\n",
    "    # Expanded parameter grid\n",
    "    param_grid = {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [None, 5, 10, 15, 20, 25, 30],\n",
    "        'min_samples_split': [2, 5, 10, 15, 20],\n",
    "        'min_samples_leaf': [1, 2, 5, 10, 15],\n",
    "        'max_features': [None, 'sqrt', 'log2', 0.5, 0.75]\n",
    "    }\n",
    "    ```\n",
    "    - Et udvidet parametergrid specificeres for at dække et bredt udvalg af mulige værdier for forskellige hyperparametre. Dette gøres for at se om vi kan få en bedre accuracy.\n",
    "\n",
    "3. **Opsætning af GridSearchCV:**\n",
    "    ```python\n",
    "    # Grid search with more extensive grid\n",
    "    grid_search = GridSearchCV(estimator=DecisionTreeClassifier(random_state=42),\n",
    "                               param_grid=param_grid, \n",
    "                               cv=5,\n",
    "                               verbose=2,  # Increase verbosity to see more details during the fitting\n",
    "                               scoring='accuracy',\n",
    "                               n_jobs=-1)  # Use all available CPU cores\n",
    "    ```\n",
    "    - `GridSearchCV` initialiseres med beslutningstræ-klassifikatoren og det definerede parametergrid. Krydvalidering sættes til 5 folde (cv=5),og scoren er nøjagtighed (`accuracy`). `n_jobs=-1` betyder, at alle tilgængelige CPU-kerner bruges til beregningen.\n",
    "\n",
    "4. **Fit GridSearchCV:**\n",
    "    ```python\n",
    "    # Fit GridSearchCV\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    ```\n",
    "    - Grid Search fit-tes til træningsdatasættet for at finde de bedste hyperparametre.\n",
    "\n",
    "5. **Output af de bedste parametre og score:**\n",
    "    ```python\n",
    "    # Output the best parameters and the best score\n",
    "    print(\"Best parameters:\", grid_search.best_params_)\n",
    "    print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "    ```\n",
    "    - De bedste parametre og den bedste krydsvalideringsscore udskrives.\n",
    "\n",
    "6. **Evaluering på testdatasættet:**\n",
    "    ```python\n",
    "    # Evaluate on the test set using the best parameters\n",
    "    best_tree = grid_search.best_estimator_\n",
    "    y_pred = best_tree.predict(X_test)\n",
    "    print(\"Test Accuracy with Best Parameters:\", accuracy_score(y_test, y_pred))\n",
    "    ```\n",
    "    - Den bedste model anvendes på testdatasættet for at evaluere nøjagtigheden.\n",
    "\n",
    "7. **Visualisering af det optimerede beslutningstræ:**\n",
    "    ```python\n",
    "    # Optionally, visualize the optimized decision tree\n",
    "    dot_data = export_graphviz(best_tree, out_file=None, \n",
    "                               feature_names=X.columns,  \n",
    "                               class_names=best_tree.classes_,\n",
    "                               filled=True, rounded=True, special_characters=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    graph.render('decision_tree_more_optimized', format='png')\n",
    "    ```\n",
    "    - Det optimerede beslutningstræ visualiseres og gemmes som en PNG-fil.\n",
    "\n",
    "## Resultater\n",
    "\n",
    "Efter at have kørt Grid Search med det udvidede parametergrid, blev følgende bedste parametre fundet:\n",
    "- **Best parameters:** `{'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 2}`\n",
    "- **Best cross-validation score:** `0.62`\n",
    "- **Test Accuracy with Best Parameters:** `0.61`\n",
    "\n",
    "Den optimerede beslutningstræ-model er visualiseret i filen `decision_tree_more_optimized.png`.\n",
    "\n",
    "Dette viser, hvordan Grid Search kan bruges til at forbedre en model ved at systematisk afprøve forskellige kombinationer af hyperparametre og vælge den bedste baseret på krydsvalideringsscoren. \n",
    "Vi fik en smule bedre accuracy. Dog ikke meget. Det betyder måske at modellen ikke kan forbedres mere med det nuværende data, men dette er ikke sikkert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1750 candidates, totalling 8750 fits\n",
      "Best parameters: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
      "Best cross-validation score: 0.62\n",
      "Test Accuracy with Best Parameters: 0.6073237241916635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'decision_tree_more_optimized.png'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Expanded parameter grid\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 5, 10, 15, 20, 25, 30],\n",
    "    'min_samples_split': [2, 5, 10, 15, 20],\n",
    "    'min_samples_leaf': [1, 2, 5, 10, 15],\n",
    "    'max_features': [None, 'sqrt', 'log2', 0.5, 0.75]\n",
    "}\n",
    "\n",
    "# Grid search with more extensive grid\n",
    "grid_search = GridSearchCV(estimator=DecisionTreeClassifier(random_state=42),\n",
    "                           param_grid=param_grid, \n",
    "                           cv=5,\n",
    "                           verbose=2,  # Increase verbosity to see more details during the fitting\n",
    "                           scoring='accuracy',\n",
    "                           n_jobs=-1)  # Use all available CPU cores\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Output the best parameters and the best score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "# Evaluate on the test set using the best parameters\n",
    "best_tree = grid_search.best_estimator_\n",
    "y_pred = best_tree.predict(X_test)\n",
    "print(\"Test Accuracy with Best Parameters:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Optionally, visualize the optimized decision tree\n",
    "dot_data = export_graphviz(best_tree, out_file=None, \n",
    "                           feature_names=X.columns,  \n",
    "                           class_names=best_tree.classes_,\n",
    "                           filled=True, rounded=True, special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render('decision_tree_more_optimized', format='png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. **Import af nødvendige moduler:**\n",
    "    ```python\n",
    "    import graphviz\n",
    "    from sklearn.tree import export_graphviz\n",
    "    ```\n",
    "    - `graphviz` bruges til at generere og visualisere beslutningstræet.\n",
    "    - `export_graphviz` fra `sklearn.tree` bruges til at eksportere beslutningstræet i DOT-format, som Graphviz kan læse.\n",
    "\n",
    "2. **Eksport af beslutningstræet til DOT-format:**\n",
    "    ```python\n",
    "    # Visualize the optimized decision tree\n",
    "    dot_data = export_graphviz(best_tree, out_file=None, \n",
    "                               feature_names=X.columns,  \n",
    "                               class_names=best_tree.classes_,\n",
    "                               filled=True, rounded=True, special_characters=True)  # Control the size as previously discussed\n",
    "    ```\n",
    "    - `export_graphviz` funktion eksportere det trænede beslutningstræ (`best_tree`) til DOT-format. Parametrene inkluderer:\n",
    "      - `feature_names=X.columns`: Navnene på de features, der bruges i modellen.\n",
    "      - `class_names=best_tree.classes_`: Navnene på klasserne i målsættet.\n",
    "      - `filled=True`: Noderne fyldes med farver, der repræsenterer forskellige klasser.\n",
    "      - `rounded=True`: Noderne har afrundede hjørner.\n",
    "      - `special_characters=True`: Tillader specielle tegn i output.\n",
    "\n",
    "3. **Generering af grafen og gemme den som en PNG-fil:**\n",
    "    ```python\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    graph_path = graph.render('decision_tree_more_optimized', format='png')\n",
    "    ```\n",
    "    - `graphviz.Source` initialiserer en Graphviz kildeobjekt med DOT-dataen (`dot_data`).\n",
    "    - `graph.render` genererer grafen og gemmer den som en PNG-fil med navnet `decision_tree_more_optimized`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# Visualize the optimized decision tree\n",
    "dot_data = export_graphviz(best_tree, out_file=None, \n",
    "                           feature_names=X.columns,  \n",
    "                           class_names=best_tree.classes_,\n",
    "                           filled=True, rounded=True, special_characters=True)  # Control the size as previously discussed\n",
    "\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph_path = graph.render('decision_tree_more_optimized', format='png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Import af nødvendige moduler:**\n",
    "    ```python\n",
    "    from joblib import dump\n",
    "    ```\n",
    "    - `dump` funktionen fra `joblib` modulet bruges til at gemme Python-objekter til en fil.\n",
    "\n",
    "2. **Gemme den trænede model:**\n",
    "    ```python\n",
    "    dump(tree_classifier, 'decision_tree_model.joblib')\n",
    "    ```\n",
    "    - `dump` funktionen gemmer `tree_classifier` modellen til en fil med navnet `decision_tree_model.joblib`.\n",
    "    - Filen `decision_tree_model.joblib` kan senere indlæses for at genbruge den trænede model uden at skulle træne den igen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['decision_tree_model.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dump(tree_classifier, 'decision_tree_model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
